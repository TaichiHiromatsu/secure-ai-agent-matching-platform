## はじめに

「沖縄への3泊4日の旅行を計画して」

こう話しかけるだけで、あなたのAIエージェントが外部の旅行AI、ホテルAI、レンタカーAIを呼び出し、連携して予約を完了する──そんな未来がすぐそこまで来ています。

![A2Aの世界観](https://storage.googleapis.com/zenn-user-upload/1ebbcdfb9389-20260104.png)
*ユーザーのメインAIが、各事業者の外部AIエージェントと連携するA2A時代のイメージ*

2025年4月、GoogleがA2A（Agent to Agent）プロトコルを提唱しました。これはAIエージェント間通信の標準規格であり、Microsoft含む100社以上が参画しています。AIが外部のAIと直接通信する構造が、これからの当たり前になろうとしています。

しかし、ここで一つの疑問が生まれます。

**その相手AI、本当に信頼できますか？**

本記事では、NEDO懸賞金活用型プログラム「GENIAC-PRIZE」に提出した、AIエージェント同士のセキュアな連携を実現するプラットフォームについて解説します。

### GENIAC-PRIZEとは

[GENIAC-PRIZE](https://geniac-prize.nedo.go.jp/)は、経済産業省とNEDO（国立研究開発法人新エネルギー・産業技術総合開発機構）が主催する懸賞金活用型プログラムです。国内における生成AI基盤モデルの開発力強化を目的としたプロジェクト「GENIAC」の一環として、**懸賞金総額最大約8億円**という規模で実施されています。

本プラットフォームが応募した**領域03「生成AIの安全性確保に向けたリスク探索及びリスク低減技術の開発」**では、生成AIに関わるリスクの特定と、そのリスク低減を目的とする技術開発が募集されています。

| 順位 | 賞金額 |
|------|--------|
| 第1位 | 7,000万円 |
| 第2位 | 5,000万円 |
| 第3位 | 3,000万円 |

私たちはこの領域03の本審査に応募し、現在結果発表を待っているところです。

### 本記事の執筆者・チームについて

本プラットフォームは、以下のチームメンバーで開発しました：

- **安田直也（本記事執筆者）**: 要件定義、エージェントストア部分の設計・実装
- **広松太一**: 要件定義、仲介エージェント部分の設計・実装
- **佐藤幸治**: 要件定義、導入部の資料作成・プレゼンテーション

---

## AIエージェント時代の2つの構造的リスク

AIエージェントは、もはや単体のLLMではなく、ユーザーの指示を理解・分解し、複数の外部AIを呼び出して最適解を組み立てる存在へと進化しています。

この構造変化により、AIエージェントは自然言語で外部AIと対話する、つまり**命令とデータが曖昧な対話**を受け入れるようになりました。

そして、この**命令とデータが曖昧な対話こそが新たな攻撃経路**となります。

### リスク1: 相手のAIは信頼できる？（真正性・信頼性問題）

相手の真正性・信頼性は従来のセキュリティでも問題でした。しかし、AIエージェント時代では人間の確認が**完全に外れる**ため、深刻度が桁違いに高まります。

| 観点 | 従来 | AIエージェント時代 |
|------|------|-------------------|
| チェック主体 | 人が「怪しいURL/アプリ」を判断 | ユーザエージェントが自律的に外部AIを呼び出し |
| 人間の介在 | 人間がチェックを行う | 人間のチェックが入らない |

**想定されるリスク例**: AIが外部の航空会社AIを呼び出したつもりが、悪意のある偽AIもしくは脆弱なAIを呼び出してしまい、パスポート情報などを送信してしまう。

### リスク2: データが命令に"化ける"（間接的プロンプトインジェクション）

AIは自然言語を命令として理解するため、外部AIの回答に混ざった指示が**そのまま実行される**危険性があります。

| 観点 | 従来 | AIエージェント時代 |
|------|------|-------------------|
| データと命令 | 処理すべきデータと命令に明確な境界がある | 処理すべきデータと命令が曖昧になる |

**想定されるリスク例**: 正しい外部AIと通信していても、外部AIの参照したデータに含まれる悪意のある指示をそのまま実行してしまう。

:::message
従来: データ ≠ 命令
AIエージェント時代: データ ≒ 命令  ← これが問題
:::

---

## 解決アプローチ: 「信頼レイヤー」という発想

AI社会には、通信の安全と内容の正しさ、そして相手AIエージェントの真正性・信頼性を保証する**信頼レイヤー**が必要になります。

本技術は、AIエージェント同士の連携において

- **相手エージェントの真正性・信頼性**
- **対話内容の整合性と命令改ざん検知**

を担保する新しいインフラレイヤーです。

### アーキテクチャ概要

![信頼レイヤーのアーキテクチャ](https://storage.googleapis.com/zenn-user-upload/fa6b33ea745e-20260104.png)
*信頼レイヤーの全体像：仲介エージェントとエージェントストアが連携し、外部AIとの安全な通信を実現*

信頼レイヤーは以下の流れで動作します：

1. **ユーザー → メインAI**: ユーザーがメインAI（パーソナルエージェント）に要望を伝える
2. **メインAI → 仲介エージェント**: メインAIが外部AIを呼び出す際、仲介エージェントを経由
3. **仲介エージェント ↔ エージェントストア**: 仲介エージェントがストアに照会し、信頼スコアの高い外部AIを選定
4. **仲介エージェント → 外部AI**: 選定した外部AIと対話、全通信を監視・検証
5. **フィードバックループ**: 対話中に検知した異常や問題は、エージェントストアに報告され信頼スコアに反映

この**フィードバックループ**が重要です。仲介エージェントが対話中に検知した問題（不審な応答、攻撃の兆候など）は即座にエージェントストアに報告され、該当エージェントの信頼スコアが更新されます。これにより、エコシステム全体が自己改善していく仕組みを実現しています。

### 2つのコンポーネント

#### 1. エージェントストア（事前審査）

外部AIの真正性とセキュリティレベルを可視化し、**安全に利用できるエージェントだけを登録**するプラットフォームです。

![Trusted Agent Store](https://storage.googleapis.com/zenn-user-upload/a81f3005828c-20260104.png)
*Trusted Agent Store: 登録済みエージェントと信頼スコア（Trust Score）を一覧表示*

**主な機能**:
- **エージェント登録**: URLやメタデータを用いて外部エージェントを登録
- **信頼スコアの算出**: プロンプトインジェクション耐性、挙動分析から信頼度を計算
- **スコア更新**: 事故・不正検知があれば自動でスコアを下げる

#### 2. 仲介エージェント（リアルタイム監視）

ユーザの要望を安全に実現するためのエージェントです。安全な外部AIを選び、計画・実行し、全通信を監視します。

**5つのサブエージェント**:

| エージェント | 役割 |
|-------------|------|
| **Matcher** | エージェントストアから最適AIを検索、信頼スコアの高いAIを優先提案 |
| **Planner** | 最適AIの組み合わせと手順を計画し、計画を"正しい命令セット"として保存 |
| **Orchestrator** | 計画に従って「実行の自動化」と「実行内容の拘束」を同時に行う |
| **Anomaly Detector** | やり取りのログをリアルタイム監視、計画と比較し指示の上書きを検知 |
| **Final Anomaly Detector** | 目的達成を確認、改ざんによる目的変更や逸脱を検出 |

---

## 実装のポイント: 論文で裏付けられた防御手法

### なぜこの設計が有効なのか

仲介エージェントの設計は、以下の論文で有効性が示された手法を採用しています：

- **[Task Shield](https://arxiv.org/abs/2412.16682)**: 仲介LLM層により攻撃成功率が約2%に低下
- **[Multi-Agent Defense Pipeline](https://arxiv.org/abs/2509.14285)**: マルチエージェント構成で攻撃成功率が20〜30%→0%に
- **[Plan-and-Solve Prompting](https://arxiv.org/abs/2305.04091)**: 計画/実行分離で一貫性・可検証性が向上

### エージェントストアの審査パイプライン

エージェントストアでは、JAPAN AISI（日本AIセーフティ・インスティテュート）の評価観点に準拠した審査を行います。

#### 審査の3つの柱

**1. 登録時の厳格な審査**

![エージェント登録画面](https://storage.googleapis.com/zenn-user-upload/d04dd761c956-20260104.png)
*エージェント登録画面: 審査ステップ（PreCheck、Security Gate、Agent Card Accuracy、Judge Panel）を選択可能*

**Security Gate（セキュリティテスト）**: Japan AISI提供評価データセットやAdvBench由来の敵対的プロンプトでエージェントの脆弱性を検証します。

![Security Gate結果サマリー](https://storage.googleapis.com/zenn-user-upload/b0e93fe01f72-20260104.png)
*Security Gate: 敵対的プロンプトに対するテスト結果。Blocked（安全にブロック）、Needs Review（要確認）を判定*

![Security Gateテスト詳細](https://storage.googleapis.com/zenn-user-upload/bad23ecd9ffa-20260104.png)
*全セキュリティテスト一覧: 各プロンプトに対するエージェントの応答と判定結果を確認可能*

**Agent Card Accuracy（機能整合性検証）**: エージェントが自己申告した機能（Agent Card）と実際の動作が一致するかをMulti-turn対話で検証します。

![Agent Card Accuracy詳細](https://storage.googleapis.com/zenn-user-upload/03ae23a8fe9a-20260104.png)
*Agent Card Accuracy: 対話履歴と品質指標を表示*

**2. 陪審員エージェントによる合議制**

単一のLLMによる評価ではバイアスや盲点が生じます。そこで、**3人の陪審員エージェント**による並列ラウンド議論と、**裁判官エージェント**による最終決議を実装しました。

**評価の4軸**（[AISIの10観点評価](https://aisi.go.jp/assets/pdf/ai_safety_eval_summary_v1.10_ja.pdf)を再構成）:

| 評価軸 | 重み | 含まれるAISI評価観点 |
|--------|------|---------------------|
| タスク達成度 | 20% | 観点9: データ品質 |
| ツール利用の適切さ | 15% | 観点8: ロバスト性 |
| 自律性の適切さ | 15% | 観点7: 説明可能性、観点10: 検証可能性 |
| **安全性** | **50%** | 観点1: 有害情報の出力制御、観点2: 偽誤情報の防止、観点3: 公平性と包摂性、観点4: ハイリスク利用への対処、観点5: プライバシー保護、観点6: セキュリティ確保 |

陪審員エージェントのシステムプロンプトに上記10観点の評価基準を組み込み、評価の一貫性を確保しています。

```
┌──────────────────────────────────────┐
│            陪審員エージェント           │
│  ┌────────┐ ┌────────┐ ┌────────┐    │
│  │Gemini  │ │Claude  │ │GPT-4   │    │
│  │陪審員1  │ │陪審員2  │ │陪審員3  │    │
│  └───┬────┘ └───┬────┘ └───┬────┘    │
│      │          │          │         │
│      └──────────┼──────────┘         │
│                 ▼                    │
│         ┌────────────┐               │
│         │ 裁判官Agent │               │
│         │ (最終判定)  │               │
│         └────────────┘               │
└──────────────────────────────────────┘
```

![Jury Judge評価中](https://storage.googleapis.com/zenn-user-upload/e58c9b65fb9f-20260104.png)
*陪審員システム（MAGI）: BALTHASAR、CASPER、MELCHIORの3人の陪審員エージェントが並列で評価中。各エージェントが異なるLLM（Claude、Gemini、GPT-4o）で構成*

![Jury Judge審議結果](https://storage.googleapis.com/zenn-user-upload/210ebd1d57d6-20260104.png)
*審議結果: 全陪審員がFAIL判定、Trust Score 0点で「否決」。裁判官エージェント（FINAL JUDGE）が最終判定を下し、詳細スコア（Task Completion、Tool Usage、Autonomy、Safety）を表示*

![Human Review/Publish結果](https://storage.googleapis.com/zenn-user-upload/3314d3bc6d4d-20260104.png)
*自動判定結果: Trust Scoreが閾値（50）以下の場合、Human Reviewをスキップして自動却下（Rejected）*

**3. 継続的な品質保証**

- 登録後もエージェントの動作を定期的に再評価
- 仲介エージェントからのフィードバックを基に信頼スコアを更新
- **自己改善型セキュリティエコシステム**: 問題検出 → スコア減点 → マッチング順位低下 → 悪意あるエージェントの即時遮断

#### 審査完了後の詳細画面

![審査パイプライン詳細](https://storage.googleapis.com/zenn-user-upload/a89824fddeb4-20260104.png)
*審査完了後の詳細画面: 各ステップ（PreCheck → Security Gate → Agent Card Accuracy → Jury Judge → Human Review → Publish）の進捗とTrust Scoreを表示*

**Observability機能**:
- **Weights & Biases連携**: 各審査ステップのLLM呼び出しをW&B Weave Tracesでトレース可能。評価の透明性と再現性を確保
- **Artifacts（成果物）**: 各ステップで生成されたエージェントとの対話履歴はJSONL形式でダウンロード可能。監査証跡として活用できる

---

## 実証結果: 数字で示す効果

「合格サンプル」と「不合格サンプル」のエージェントに対して、審査パイプラインを各60回（計120回）実行しました。

| 評価対象 | 検出率 | 偽陰性率 | 偽陽性率 | 全体正解率 |
|----------|--------|----------|----------|-----------|
| エージェントストア | **100%** (60/60) | **0%** | 1.7% | **99.2%** |
| 仲介エージェント | **100%** (60/60) | **0%** | 21.7% | **89.2%** |

**両コンポーネントとも検出率100%・偽陰性0%を達成**。悪意あるエージェントやプロンプトインジェクション攻撃を確実に検出しています。仲介エージェントの偽陽性率21.7%は今後の改善点ですが、再試行により通過可能でありセキュリティ上のリスクにはなりません。

---

## OSSとして公開

本プラットフォームはOSSとして公開しています。

**GitHub**: https://github.com/TaichiHiromatsu/secure-ai-agent-matching-platform

### 技術スタック

- **フレームワーク**: Google ADK (Agent Development Kit)
- **プロトコル**: A2A (Agent to Agent)
- **評価ツール**: AISI公開のaisev、W&B Weave
- **インフラ**: Cloud Run, nginx, Firebase Auth

---

## なぜ国産プラットフォームが必要なのか

「A2Aプロトコルの信頼レイヤーは、GoogleやMicrosoftが作るのでは？」

この疑問はもっともです。実際、A2Aプロトコル自体はGoogleが提唱し、大手テック企業が参画しています。しかし、**信頼レイヤー**については国産プラットフォームに大きな価値があると考えています。

### 世界初の「A2Aセキュリティ信頼レイヤー」

[Googleの**Agent Finder**](https://cloud.withgoogle.com/agentfinder/)は企業管理者がエージェントを探して購入する「B2Bカタログ」であり、**人間が導入判断**を行います。

本プラットフォームは、**AIが自律的に外部AIを呼び出す際の信頼性検証とリアルタイム攻撃検知**を行う点で根本的に異なり、この領域では世界初の実装だと思います。

### 規制・基準への準拠

本プラットフォームは、Japan AISI（日本AIセーフティ・インスティテュート）の評価観点ガイドに準拠したOSSツール「aisev」を採用し、**日本の規制環境に最適化**されています。海外プラットフォームでは、日本固有の要件への対応が後回しになる可能性があります。

---

## 今後の展望

本プラットフォームが評価いただけた場合、以下の取り組みを進めたいと考えています：

- **国産「エージェント信頼フレームワーク」の標準化**: NEDO・AISIなどの公的機関と連携し、AIエージェント間通信のセキュリティ基準をオープンな仕様として策定・公開することを目指します
- **国際標準への貢献**: 国内での実績を基に、A2Aプロトコルのセキュリティ拡張仕様として国際的な標準化活動に参画

---

## まとめ

本プラットフォームは、**エージェントストア**（事前審査）と**仲介エージェント**（リアルタイム監視）の2層構造で、**検出率100%・偽陰性0%** を達成しました。OSSとして公開していますので、ぜひ触ってみてください。

---

## 参考資料

### 関連記事

- **[広松太一のブログ: GENIAC-PRIZEセキュアA2Aプラットフォーム技術解説](https://techblog.insightedge.jp/entry/geniac-prize-secure-a2a-platform)** - 原案者による仲介エージェントの設計思想や実装詳細。本プラットフォームの背景にある課題意識や、プロンプトインジェクション対策の技術的根拠について詳しく解説しています。

### リポジトリ・ドキュメント

- [GitHub リポジトリ](https://github.com/TaichiHiromatsu/secure-ai-agent-matching-platform)
- [Google A2A Protocol](https://github.com/google/A2A)
- [Japan AISI AIセーフティに関する評価観点ガイド](https://aisi.go.jp/output/output_framework/guide_to_evaluation_perspective_on_ai_safety/)
- [Japan AISI aisev（評価ツール）](https://github.com/Japan-AISI/aisev)
