# NEDO質問への回答案：プランナーのアルゴリズムと対応可能なタスク複雑度

---

## 質問

> 仲介エージェントのプランナーは、どのようなアルゴリズムで実行されるのでしょうか。どの程度複雑なタスクに対応可能でしょうか？

---

## 回答案

### 1. なぜLLMベースなのか

プランナーは、従来型のルールベースアルゴリズムではなく、**LLM（Gemini 2.5 Pro）の推論による計画生成**を採用しています。

この設計判断の理由は、AIエージェント連携における計画生成が**本質的にLLMでしか対応できない問題**だからです。ユーザーの要求は自然言語で与えられ、外部エージェントの能力記述（Agent Card）も自然言語です。「沖縄への3泊4日の旅行計画を作って」というリクエストから、どのエージェントをどの順序で呼び出すべきかを判断するには、自然言語の意味理解・タスク分解・エージェント能力のマッチングを一貫して行う必要があり、これはルールベースの手続きでは実現困難です。

そのため、プランナーの精度向上は主に**プロンプトチューニング**によって行っています。具体的には、タスク分解の粒度、各ステップの入出力仕様の記述方法、依存関係の定義方法などをプロンプト内で指示し、LLMの出力品質を制御しています。

---

### 2. 具体的な処理フロー：何を呼び出し、何を行っているか

仲介エージェント全体は5つのサブエージェントで構成されており、プランナーはその計画生成フェーズを担います。以下、ユーザーリクエストを受けてから結果を返すまでの全体フローを説明します。

```
ユーザー → ①Matcher → ②Planner → ③Orchestrator → ④Anomaly Detector → ⑤Final Anomaly Detector → ユーザー
```

**① Matcher（エージェント選定）**

エージェントストアのAPIを呼び出し（`search_agent_store`ツール）、ストアに登録済みの全エージェントから要件に適合するものを検索します。各エージェントのスキルタグ・信頼スコア（0〜100）・能力記述を取得し、`rank_agents_by_trust`ツールで信頼スコア順にランキング。閾値以下のエージェントはフィルタリングで除外します。さらに`calculate_matching_score`ツールで、スキルの重複度・入出力モードの互換性を加味した適合度スコアを算出します。

**② Planner（計画生成）** ← 質問の対象

Matcherが選定したエージェント群を受けて、LLMがステップごとの実行計画を生成します。各ステップには担当エージェント名、入力データ、期待出力、先行ステップへの依存関係を含みます。生成された計画は`save_plan_as_artifact`ツールで**Markdownファイルとして永続化**します。

**③ Orchestrator（計画実行）**

保存された計画ファイルを`load_plan_from_artifact`で読み込み、各ステップを順に実行します。外部エージェントとの通信は`invoke_a2a_agent`ツールがA2Aプロトコル（Google ADKのRemoteA2aAgent）経由で行います。全通信のレスポンスは`after_tool_callback`（セキュリティコールバック）を通じ、**独立したJudge Agent**がリアルタイムで安全性を判定します。

**④ Anomaly Detector（逸脱検知）**

Orchestratorの実行中、`compare_with_plan`ツールが計画ファイルと実際の実行を比較し、計画からの逸脱（想定外のエージェント呼び出し、出力の大幅な乖離等）を検知します。`detect_suspicious_behavior`ツールがプロンプトインジェクションパターンの正規表現マッチングも行います。

**⑤ Final Anomaly Detector（最終検証）**

全ステップ完了後、計画全体と実行結果の整合性を総合検証し、ACCEPT / REJECT / REVIEW の最終判定を行います。

---

### 3. 計画のファイル永続化：セキュリティとスケーラビリティの両立

プランナーの最も重要な設計上の特徴は、**計画をLLMのコンテキストウィンドウ内に留めず、Markdownファイルとして外部に永続化する**点です。

この設計には2つの意図があります。

**セキュリティ面：** 計画がファイルとして固定されているため、Orchestratorは実行時に計画外の行動を取りにくくなります。Anomaly Detectorは、このファイルを「正しい命令セット」の基準線（ベースライン）として参照し、逸脱を検知します。これは学術的には「Plan-Then-Execute（P-t-E）パターン」と呼ばれ、間接的プロンプトインジェクションに対する頑健性が論文（arXiv:2506.08837）で示されています。

**スケーラビリティ面：** 計画がファイルに永続化されているため、**計画の複雑さはLLMのコンテキストウィンドウ長に依存しません**。Orchestratorは各ステップの実行時に必要な部分だけを`parse_plan_for_step`で読み出すため、全体計画がどれほど大きくても各ステップの実行には影響しません。

---

### 4. 対応可能なタスク複雑度：LLMの進化とともにスケールする

#### 現時点での対応範囲

現在は、5〜10ステップ・3〜5エージェント連携の逐次的なタスクに対応しています。

**対応例：**
- 「沖縄旅行の計画」（旅行AI→ホテルAI→レンタカーAIの順次連携）
- 「営業資料の作成」（CRM AI→提案書AI→契約書AIのパイプライン処理）

#### 複雑なタスクへの対応はLLMの性能向上に比例する

本プラットフォームのアーキテクチャにおいて、タスク複雑度のボトルネックは**Plannerが計画を生成する段階のLLMの推論能力**です。

- 計画生成の品質（タスク分解の適切さ、依存関係の正確さ）はLLMの推論能力に依存
- しかし一度計画がファイルに書き出されれば、実行・監視の各フェーズはステップ単位で動作するため、計画全体の規模に制約されない
- つまり、**LLMのコンテキストウィンドウの拡大や推論能力の向上に伴い、より複雑な計画を生成可能になり、プラットフォーム全体が扱えるタスク複雑度も自然に向上する**

具体的には、現在のGemini 2.5 Proの100万トークンのコンテキストウィンドウでも数十ステップの計画生成は可能ですが、LLMの推論精度（タスク分解の正確さ）がボトルネックになるため、実用的には5〜10ステップ程度としています。今後のLLMの進化により、この上限は段階的に引き上げられる見込みです。

#### 今後の技術拡張

- **並列実行**：依存関係がないステップの並列処理
- **条件分岐**：計画フォーマットへの条件分岐構文の導入
- **安全なリプランニング**：実行結果に応じた計画修正（修正計画もファイル保存し、逸脱検知の基準線を更新）

---

### まとめ

| 観点 | 内容 |
|------|------|
| **アルゴリズム基盤** | LLM推論（Gemini 2.5 Pro）＋プロンプトチューニング |
| **LLMである理由** | 自然言語によるタスク分解・エージェント能力マッチングはルールベースでは不可能 |
| **主要ツール** | `search_agent_store`, `save_plan_as_artifact`, `invoke_a2a_agent`, `compare_with_plan` 等 |
| **計画の永続化** | Markdownファイルとして保存 → セキュリティ基準線 + コンテキスト制約からの解放 |
| **現在の対応範囲** | 5〜10ステップ、3〜5エージェント連携の逐次タスク |
| **スケーラビリティ** | LLMの推論能力向上に比例して、対応可能なタスク複雑度も向上 |

---

*作成日: 2026-02-28*
